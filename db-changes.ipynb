{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from datetime import datetime, timedelta  # Make sure this line is added\n",
    "import pytz\n",
    "from faker import Faker\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable to the path of the service account key\n",
    "# set GOOGLE_APPLICATION_CREDENTIALS=C:\\default/path/to/service/account/key.json\n",
    "\n",
    "# Specify the path to your service account key\n",
    "cred_path = r\"default/path/to/service/account/key.json\"\n",
    "\n",
    "# Use the Certificate method to load the service account key\n",
    "cred = credentials.Certificate(cred_path)\n",
    "\n",
    "# Initialize the Firebase app with the credentials\n",
    "firebase_admin.initialize_app(cred)\n",
    "\n",
    "# Access Firestore\n",
    "db = firestore.client()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from Table - Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document data: {'lastName': 'McMohan', 'firstName': 'Jamie', 'id': 'UID52612988', 'interests': ['programming', 'stamp collection'], 'lastLogin': DatetimeWithNanoseconds(2023, 12, 15, 10, 3, 1, tzinfo=datetime.timezone.utc), 'locationCity': 'Toronto', 'discipline': 'Data Analytics', 'updatedAt': DatetimeWithNanoseconds(2024, 4, 5, 0, 19, 7, tzinfo=datetime.timezone.utc), 'dob': DatetimeWithNanoseconds(1997, 12, 23, 0, 0, tzinfo=datetime.timezone.utc), 'industry': 'mining', 'profilePhoto': 'image1', 'expertise': 'python', 'createdAt': DatetimeWithNanoseconds(2024, 4, 13, 23, 19, 18, tzinfo=datetime.timezone.utc), 'email': 'matthewsdonald@yahoo.com'}\n"
     ]
    }
   ],
   "source": [
    "# Reference to a specific document\n",
    "doc_ref = db.collection('Users').document('CiMRgVGMNpfLiRZ0D03Q')\n",
    "doc = doc_ref.get()\n",
    "\n",
    "# Check if the document exists and print its data\n",
    "if doc.exists:\n",
    "    print('Document data:', doc.to_dict())\n",
    "else:\n",
    "    print('No such document!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from Table - Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document data: {'createdAt': DatetimeWithNanoseconds(2022, 4, 24, 1, 13, 52, 677000, tzinfo=datetime.timezone.utc), 'members': ['Fahd', 'Alberto', 'Daniel', 'Yuan', 'Rowan', 'Jane', 'Vidya', 'Orkhan'], 'communityId': '000001', 'updatedAt': DatetimeWithNanoseconds(2024, 3, 31, 21, 18, 24, 794000, tzinfo=datetime.timezone.utc), 'communityName': 'Data'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "doc_ref = db.collection('Communities').document('202IF7YC92eRfw9egHCO')\n",
    "doc = doc_ref.get()\n",
    "\n",
    "# Check if the document exists and print its data\n",
    "if doc.exists:\n",
    "    print('Document data:', doc.to_dict())\n",
    "else:\n",
    "    print('No such document!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all user IDs from the Users collection\n",
    "users_ref = db.collection('Users')\n",
    "users = users_ref.stream()\n",
    "\n",
    "user_ids = [user.get('id') for user in users if user.exists]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intialise Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the Communities table with Fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete.\n"
     ]
    }
   ],
   "source": [
    "# Code commented out to prevent accidental execution\n",
    "# Generate data for 10 communities\n",
    "# for i in range(10):\n",
    "#     # Create timestamps between Jan 2020 to Dec 2022 for createdAt\n",
    "#     start_date = datetime(2020, 1, 1)\n",
    "#     end_date = datetime(2022, 12, 31)\n",
    "#     time_between_dates = end_date - start_date\n",
    "#     days_between_dates = time_between_dates.days\n",
    "#     random_number_of_days = random.randrange(days_between_dates)\n",
    "#     created_at = start_date + timedelta(days=random_number_of_days)\n",
    "\n",
    "#     # Create timestamps between 2023 to 2024 for updatedAt\n",
    "#     start_update_date = datetime(2023, 1, 1)\n",
    "#     end_update_date = datetime(2024, 12, 31)\n",
    "#     time_between_updates = end_update_date - start_update_date\n",
    "#     days_between_updates = time_between_updates.days\n",
    "#     random_number_of_update_days = random.randrange(days_between_updates)\n",
    "#     updated_at = start_update_date + timedelta(days=random_number_of_update_days)\n",
    "\n",
    "#     # Randomly select member IDs from the fetched user IDs\n",
    "#     member_ids = random.sample(user_ids, random.randint(50, 100))\n",
    "\n",
    "#     # Generate community IDs\n",
    "#     community_id = f'00000{random.randint(10, 99)}'\n",
    "\n",
    "#     # Generate random community names\n",
    "#     community_name = fake.word().capitalize()\n",
    "\n",
    "#     # Create document in Firestore\n",
    "#     community_ref = db.collection('Communities').document()\n",
    "#     community_ref.set({\n",
    "#         'createdAt': created_at,\n",
    "#         'updatedAt': updated_at,\n",
    "#         'members': member_ids,\n",
    "#         'communityId': community_id,\n",
    "#         'communityName': community_name\n",
    "#     })\n",
    "\n",
    "# print(\"Data generation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data from Communities Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          createdAt  \\\n",
      "0  2022-04-24 01:13:52.677000+00:00   \n",
      "1         2022-09-29 00:00:00+00:00   \n",
      "2         2020-12-14 00:00:00+00:00   \n",
      "3         2021-12-16 00:00:00+00:00   \n",
      "4         2020-09-15 00:00:00+00:00   \n",
      "5         2022-01-29 00:00:00+00:00   \n",
      "6         2022-05-13 00:00:00+00:00   \n",
      "7         2022-04-26 00:00:00+00:00   \n",
      "8         2021-09-21 00:00:00+00:00   \n",
      "9         2022-09-22 00:00:00+00:00   \n",
      "10        2022-12-07 00:00:00+00:00   \n",
      "\n",
      "                                              members communityId  \\\n",
      "0   [Fahd, Alberto, Daniel, Yuan, Rowan, Jane, Vid...      000001   \n",
      "1   [UID37883100, UID75356431, UID35833983, UID565...     0000079   \n",
      "2   [UID18092847, UID46173593, UID36935153, UID870...     0000033   \n",
      "3   [UID36491462, UID80484184, UID32202512, UID398...     0000063   \n",
      "4   [UID60913427, UID27256216, UID79938371, UID871...     0000058   \n",
      "5   [UID35833983, UID50278766, UID90810398, UID110...     0000086   \n",
      "6   [UID38975172, UID14061201, UID14598015, UID895...     0000071   \n",
      "7   [UID97468961, UID34942095, UID31389026, UID543...     0000054   \n",
      "8   [UID38454297, UID19028953, UID54190844, UID747...     0000076   \n",
      "9   [UID57842425, UID89732140, UID43803187, UID573...     0000077   \n",
      "10  [UID19952648, UID81379226, UID72214264, UID577...     0000051   \n",
      "\n",
      "                          updatedAt communityName  \n",
      "0  2024-03-31 21:18:24.794000+00:00          Data  \n",
      "1         2024-08-25 00:00:00+00:00          Miss  \n",
      "2         2023-01-10 00:00:00+00:00       Pattern  \n",
      "3         2024-05-06 00:00:00+00:00          Most  \n",
      "4         2024-07-20 00:00:00+00:00          Join  \n",
      "5         2023-12-05 00:00:00+00:00          Road  \n",
      "6         2024-10-10 00:00:00+00:00        Effort  \n",
      "7         2023-05-22 00:00:00+00:00       Produce  \n",
      "8         2024-07-14 00:00:00+00:00          City  \n",
      "9         2024-10-19 00:00:00+00:00          Free  \n",
      "10        2023-04-11 00:00:00+00:00          Next  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read rows from Communities collection\n",
    "communities_ref = db.collection('Communities')\n",
    "communities = communities_ref.stream()\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over the documents and store the data in the list\n",
    "for community in communities:\n",
    "    data.append(community.to_dict())\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read again from Users collection \n",
    "\n",
    "**Read again from Users collection after having changes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastName</th>\n",
       "      <th>firstName</th>\n",
       "      <th>id</th>\n",
       "      <th>interests</th>\n",
       "      <th>lastLogin</th>\n",
       "      <th>locationCity</th>\n",
       "      <th>discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>dob</th>\n",
       "      <th>industry</th>\n",
       "      <th>profilePhoto</th>\n",
       "      <th>expertise</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>email</th>\n",
       "      <th>locationState</th>\n",
       "      <th>locationCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>McMohan</td>\n",
       "      <td>Jamie</td>\n",
       "      <td>UID52612988</td>\n",
       "      <td>[programming, stamp collection]</td>\n",
       "      <td>2023-12-15 10:03:01+00:00</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-05 00:19:07+00:00</td>\n",
       "      <td>1997-12-23 00:00:00+00:00</td>\n",
       "      <td>mining</td>\n",
       "      <td>image1</td>\n",
       "      <td>python</td>\n",
       "      <td>2024-04-13 23:19:18+00:00</td>\n",
       "      <td>matthewsdonald@yahoo.com</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graham</td>\n",
       "      <td>Laura</td>\n",
       "      <td>UID10035003</td>\n",
       "      <td>[cloud computing, cooking]</td>\n",
       "      <td>2024-10-06 01:13:43+00:00</td>\n",
       "      <td>New York</td>\n",
       "      <td>software development</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-11-13 09:47:51+00:00</td>\n",
       "      <td>1970-11-25 01:56:10+00:00</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>image378</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>2022-07-08 23:23:23+00:00</td>\n",
       "      <td>antoniowalker@example.com</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>Paul</td>\n",
       "      <td>UID10073687</td>\n",
       "      <td>[machine learning, photography]</td>\n",
       "      <td>2024-09-28 21:47:38+00:00</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>data analytics</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-11-24 05:16:17+00:00</td>\n",
       "      <td>1981-12-11 10:34:33+00:00</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>image915</td>\n",
       "      <td>C#</td>\n",
       "      <td>2023-06-14 14:25:21+00:00</td>\n",
       "      <td>fishermary@example.net</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>San Antonio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Martin</td>\n",
       "      <td>Joshua</td>\n",
       "      <td>UID10211318</td>\n",
       "      <td>[machine learning, stamp collection]</td>\n",
       "      <td>2024-11-12 06:05:14+00:00</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>data analytics</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-10-12 08:43:58+00:00</td>\n",
       "      <td>1984-10-11 12:32:31+00:00</td>\n",
       "      <td>technology</td>\n",
       "      <td>image305</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2020-03-10 07:22:15+00:00</td>\n",
       "      <td>fergusonjennifer@example.com</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Briggs</td>\n",
       "      <td>Peter</td>\n",
       "      <td>UID10254936</td>\n",
       "      <td>[AI development, volunteering]</td>\n",
       "      <td>2024-10-04 08:27:04+00:00</td>\n",
       "      <td>Miami</td>\n",
       "      <td>data analytics</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-11-13 20:07:54+00:00</td>\n",
       "      <td>1981-04-08 12:52:15+00:00</td>\n",
       "      <td>hospitality</td>\n",
       "      <td>image161</td>\n",
       "      <td>python</td>\n",
       "      <td>2023-07-05 08:48:00+00:00</td>\n",
       "      <td>marystout@example.org</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lastName firstName           id                             interests  \\\n",
       "0  McMohan     Jamie  UID52612988       [programming, stamp collection]   \n",
       "1   Graham     Laura  UID10035003            [cloud computing, cooking]   \n",
       "2   Monroe      Paul  UID10073687       [machine learning, photography]   \n",
       "3   Martin    Joshua  UID10211318  [machine learning, stamp collection]   \n",
       "4   Briggs     Peter  UID10254936        [AI development, volunteering]   \n",
       "\n",
       "                  lastLogin locationCity            discipline  experience  \\\n",
       "0 2023-12-15 10:03:01+00:00      Toronto        Data Analytics           4   \n",
       "1 2024-10-06 01:13:43+00:00     New York  software development           5   \n",
       "2 2024-09-28 21:47:38+00:00  San Antonio        data analytics           4   \n",
       "3 2024-11-12 06:05:14+00:00      Phoenix        data analytics           3   \n",
       "4 2024-10-04 08:27:04+00:00        Miami        data analytics           2   \n",
       "\n",
       "                  updatedAt                       dob       industry  \\\n",
       "0 2024-04-05 00:19:07+00:00 1997-12-23 00:00:00+00:00         mining   \n",
       "1 2024-11-13 09:47:51+00:00 1970-11-25 01:56:10+00:00  manufacturing   \n",
       "2 2024-11-24 05:16:17+00:00 1981-12-11 10:34:33+00:00     healthcare   \n",
       "3 2024-10-12 08:43:58+00:00 1984-10-11 12:32:31+00:00     technology   \n",
       "4 2024-11-13 20:07:54+00:00 1981-04-08 12:52:15+00:00    hospitality   \n",
       "\n",
       "  profilePhoto   expertise                 createdAt  \\\n",
       "0       image1      python 2024-04-13 23:19:18+00:00   \n",
       "1     image378  JavaScript 2022-07-08 23:23:23+00:00   \n",
       "2     image915          C# 2023-06-14 14:25:21+00:00   \n",
       "3     image305         SQL 2020-03-10 07:22:15+00:00   \n",
       "4     image161      python 2023-07-05 08:48:00+00:00   \n",
       "\n",
       "                          email locationState locationCountry  \n",
       "0      matthewsdonald@yahoo.com       Toronto         Toronto  \n",
       "1     antoniowalker@example.com      New York        New York  \n",
       "2        fishermary@example.net   San Antonio     San Antonio  \n",
       "3  fergusonjennifer@example.com       Phoenix         Phoenix  \n",
       "4         marystout@example.org         Miami           Miami  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read rows from Users collection\n",
    "users_ref = db.collection('Users')\n",
    "users = users_ref.stream()\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over the documents and store the data in the list\n",
    "for user in users:\n",
    "    data.append(user.to_dict())\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the field 'location' to 'locationCity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "# # Rename the 'location' field in the Users collection to 'locationCity'\n",
    "# users_ref = db.collection('Users')\n",
    "# users = users_ref.stream()\n",
    "\n",
    "# for user in users:\n",
    "#     user_ref = db.collection('Users').document(user.id)\n",
    "#     user_ref.update({\n",
    "#         'locationCity': user.get('location')\n",
    "#     })\n",
    "\n",
    "# print(\"Field renamed successfully.\")\n",
    "\n",
    "# # Separately delete the column location since we created a new column locationCity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the list of Unique cities to add state and country details from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Toronto', 'New York', 'San Antonio', 'Phoenix', 'Miami',\n",
       "       'Chicago', 'Vancouver', 'Philadelphia', 'Los Angeles', 'Houston'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the locationCity field from the Users collection\n",
    "users_ref = db.collection('Users')\n",
    "users = users_ref.stream()\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over the documents and store the data in the list\n",
    "for user in users:\n",
    "    data.append(user.to_dict())\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the locationCity field in the DataFrame\n",
    "#print(df['locationCity'])\n",
    "\n",
    "# Filter the DataFrame to display only the unique values of locationCity field\n",
    "unique_cities = df['locationCity'].unique()\n",
    "\n",
    "unique_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create State and Country mapping for each City in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of locationCity to state and locationCity to country using a dictionary\n",
    "\n",
    "# Define the mapping of locationCity to state\n",
    "city_to_state = { 'Toronto': 'Ontario', 'Vancouver': 'British Columbia', 'San Antonio' : 'Texas', 'Phoenix': 'Arizona', 'Miami':'Florida', 'Chicago':'Illinois', 'New York': 'New York', 'Philadelphia':'Pennsylvania',\n",
    "                 'Los Angeles': 'California', 'Houston': 'Texas'\n",
    "                    }  \n",
    "\n",
    "city_to_country = { 'Toronto': 'Canada', 'Vancouver': 'Canada', 'San Antonio' : 'United States', 'Phoenix': 'United States', 'Miami':'United States', 'Chicago':'United States', 'New York': 'United States', 'Philadelphia':'United States',\n",
    "                   'Los Angeles': 'United States', 'Houston': 'United States'\n",
    "                    }\n",
    "\n",
    "# Create a new column in the DataFrame to store the state\n",
    "df['locationState'] = df['locationCity'].map(city_to_state)\n",
    "\n",
    "# Create a new column in the DataFrame to store the country\n",
    "df['locationCountry'] = df['locationCity'].map(city_to_country)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if mapping has been done properly in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    locationCity     locationState locationCountry\n",
      "0        Toronto           Ontario          Canada\n",
      "1       New York          New York   United States\n",
      "2    San Antonio             Texas   United States\n",
      "3        Phoenix           Arizona   United States\n",
      "4          Miami           Florida   United States\n",
      "9        Chicago          Illinois   United States\n",
      "12     Vancouver  British Columbia          Canada\n",
      "16  Philadelphia      Pennsylvania   United States\n",
      "19   Los Angeles        California   United States\n",
      "21       Houston             Texas   United States\n"
     ]
    }
   ],
   "source": [
    "#  Check the unique combinations 'locationCity', 'locationState', 'locationCountry'\n",
    "unique_rows = df[['locationCity', 'locationState', 'locationCountry']].drop_duplicates()\n",
    "print(unique_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new columns locationState and locationCountry in the Firestore Users collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields added successfully.\n"
     ]
    }
   ],
   "source": [
    "# # Add the new columns locationState and locationCountry to the Firestore Users collection\n",
    "# users_ref = db.collection('Users')\n",
    "# users = users_ref.stream()\n",
    "\n",
    "# for user in users:\n",
    "#     user_ref = db.collection('Users').document(user.id)\n",
    "#     user_ref.update({\n",
    "#         'locationState': user.get('locationCity'),\n",
    "#         'locationCountry': user.get('locationCity')\n",
    "#     })\n",
    "\n",
    "# print(\"Fields added successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add new column 'Experience'\n",
    "\n",
    "*Add a new field 'experience' to the Users collection\n",
    "\n",
    "*Experience will be a random number between 0 and 20, with majority of the users having experience between 0 to 1 years, followed by 1 to 5 years, and then 5 to 20 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final counts: {0: 256, 1: 209, 2: 157, 3: 78, 4: 98, 5: 71, 9: 8, 8: 9, 13: 6, 6: 12, 10: 15, 11: 9, 20: 7, 17: 9, 18: 10, 7: 6, 19: 8, 16: 8, 12: 7, 15: 12, 14: 6}\n",
      "Total count: 1001\n",
      "Sample of generated numbers: [0, 4, 2, 5, 3, 0, 1, 0, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Given distribution with some predefined counts\n",
    "experience_distribution = {0: 250, 1: 200, 2: 150, 3: 75, 4: 90, 5: 65}\n",
    "\n",
    "# Total numbers to generate\n",
    "total_numbers = 1001\n",
    "\n",
    "# Calculate the sum of predefined numbers\n",
    "current_sum = sum(experience_distribution.values())\n",
    "\n",
    "# Determine how many numbers are needed to reach 1001\n",
    "remaining_numbers = total_numbers - current_sum\n",
    "\n",
    "# Assuming you want the random numbers to be from 0 to 20 as well\n",
    "all_possible_values = list(range(0, 21))  # This includes 0 to 20\n",
    "\n",
    "# Fill up the remaining numbers randomly\n",
    "for _ in range(remaining_numbers):\n",
    "    num = random.choice(all_possible_values)\n",
    "    if num in experience_distribution:\n",
    "        experience_distribution[num] += 1\n",
    "    else:\n",
    "        experience_distribution[num] = 1\n",
    "\n",
    "# Verify the distribution\n",
    "print(\"Final counts:\", experience_distribution)\n",
    "print(\"Total count:\", sum(experience_distribution.values()))\n",
    "\n",
    "# Generating the full list of experiences\n",
    "experience_list = []\n",
    "for key, count in experience_distribution.items():\n",
    "    experience_list.extend([key] * count)\n",
    "\n",
    "# Shuffle the list to randomize the order of numbers\n",
    "random.shuffle(experience_list)\n",
    "\n",
    "# Output the first 10 numbers to verify randomness\n",
    "print(\"Sample of generated numbers:\", experience_list[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the generated experience values into a new column in the Users Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience added successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add experience to the Users collection\n",
    "users_ref = db.collection('Users')\n",
    "users = users_ref.stream()\n",
    "\n",
    "# Iterate over the documents and update the experience field\n",
    "for user in users:\n",
    "    user_ref = db.collection('Users').document(user.id)\n",
    "    user_ref.update({\n",
    "        'experience': random.choice(experience_list)\n",
    "    })\n",
    "\n",
    "print(\"Experience added successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of experience values:\n",
      "experience\n",
      "0     237\n",
      "1     214\n",
      "2     170\n",
      "4     100\n",
      "3      73\n",
      "5      64\n",
      "10     21\n",
      "6      16\n",
      "8      13\n",
      "16     12\n",
      "9      11\n",
      "15     11\n",
      "11     11\n",
      "18      8\n",
      "13      7\n",
      "14      7\n",
      "20      7\n",
      "17      7\n",
      "19      6\n",
      "12      5\n",
      "7       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution of experience values:\n",
      "experience\n",
      "0     23.676324\n",
      "1     21.378621\n",
      "2     16.983017\n",
      "4      9.990010\n",
      "3      7.292707\n",
      "5      6.393606\n",
      "10     2.097902\n",
      "6      1.598402\n",
      "8      1.298701\n",
      "16     1.198801\n",
      "9      1.098901\n",
      "15     1.098901\n",
      "11     1.098901\n",
      "18     0.799201\n",
      "13     0.699301\n",
      "14     0.699301\n",
      "20     0.699301\n",
      "17     0.699301\n",
      "19     0.599401\n",
      "12     0.499500\n",
      "7      0.099900\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and 'experience' is the column of interest\n",
    "distribution = df['experience'].value_counts()\n",
    "\n",
    "# To get the distribution in percentage form\n",
    "percentage_distribution = df['experience'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Printing the results\n",
    "print(\"Distribution of experience values:\")\n",
    "print(distribution)\n",
    "\n",
    "print(\"\\nPercentage distribution of experience values:\")\n",
    "print(percentage_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the count of the 'experience' values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally check the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastName</th>\n",
       "      <th>firstName</th>\n",
       "      <th>id</th>\n",
       "      <th>interests</th>\n",
       "      <th>lastLogin</th>\n",
       "      <th>locationCity</th>\n",
       "      <th>discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>dob</th>\n",
       "      <th>industry</th>\n",
       "      <th>profilePhoto</th>\n",
       "      <th>expertise</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>email</th>\n",
       "      <th>locationState</th>\n",
       "      <th>locationCountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>McMohan</td>\n",
       "      <td>Jamie</td>\n",
       "      <td>UID52612988</td>\n",
       "      <td>[programming, stamp collection]</td>\n",
       "      <td>2023-12-15 10:03:01+00:00</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-04-05 00:19:07+00:00</td>\n",
       "      <td>1997-12-23 00:00:00+00:00</td>\n",
       "      <td>mining</td>\n",
       "      <td>image1</td>\n",
       "      <td>python</td>\n",
       "      <td>2024-04-13 23:19:18+00:00</td>\n",
       "      <td>matthewsdonald@yahoo.com</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graham</td>\n",
       "      <td>Laura</td>\n",
       "      <td>UID10035003</td>\n",
       "      <td>[cloud computing, cooking]</td>\n",
       "      <td>2024-10-06 01:13:43+00:00</td>\n",
       "      <td>New York</td>\n",
       "      <td>software development</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-11-13 09:47:51+00:00</td>\n",
       "      <td>1970-11-25 01:56:10+00:00</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>image378</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>2022-07-08 23:23:23+00:00</td>\n",
       "      <td>antoniowalker@example.com</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monroe</td>\n",
       "      <td>Paul</td>\n",
       "      <td>UID10073687</td>\n",
       "      <td>[machine learning, photography]</td>\n",
       "      <td>2024-09-28 21:47:38+00:00</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>data analytics</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-11-24 05:16:17+00:00</td>\n",
       "      <td>1981-12-11 10:34:33+00:00</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>image915</td>\n",
       "      <td>C#</td>\n",
       "      <td>2023-06-14 14:25:21+00:00</td>\n",
       "      <td>fishermary@example.net</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>San Antonio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Martin</td>\n",
       "      <td>Joshua</td>\n",
       "      <td>UID10211318</td>\n",
       "      <td>[machine learning, stamp collection]</td>\n",
       "      <td>2024-11-12 06:05:14+00:00</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>data analytics</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-10-12 08:43:58+00:00</td>\n",
       "      <td>1984-10-11 12:32:31+00:00</td>\n",
       "      <td>technology</td>\n",
       "      <td>image305</td>\n",
       "      <td>SQL</td>\n",
       "      <td>2020-03-10 07:22:15+00:00</td>\n",
       "      <td>fergusonjennifer@example.com</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Briggs</td>\n",
       "      <td>Peter</td>\n",
       "      <td>UID10254936</td>\n",
       "      <td>[AI development, volunteering]</td>\n",
       "      <td>2024-10-04 08:27:04+00:00</td>\n",
       "      <td>Miami</td>\n",
       "      <td>data analytics</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-11-13 20:07:54+00:00</td>\n",
       "      <td>1981-04-08 12:52:15+00:00</td>\n",
       "      <td>hospitality</td>\n",
       "      <td>image161</td>\n",
       "      <td>python</td>\n",
       "      <td>2023-07-05 08:48:00+00:00</td>\n",
       "      <td>marystout@example.org</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lastName firstName           id                             interests  \\\n",
       "0  McMohan     Jamie  UID52612988       [programming, stamp collection]   \n",
       "1   Graham     Laura  UID10035003            [cloud computing, cooking]   \n",
       "2   Monroe      Paul  UID10073687       [machine learning, photography]   \n",
       "3   Martin    Joshua  UID10211318  [machine learning, stamp collection]   \n",
       "4   Briggs     Peter  UID10254936        [AI development, volunteering]   \n",
       "\n",
       "                  lastLogin locationCity            discipline  experience  \\\n",
       "0 2023-12-15 10:03:01+00:00      Toronto        Data Analytics           4   \n",
       "1 2024-10-06 01:13:43+00:00     New York  software development           5   \n",
       "2 2024-09-28 21:47:38+00:00  San Antonio        data analytics           4   \n",
       "3 2024-11-12 06:05:14+00:00      Phoenix        data analytics           3   \n",
       "4 2024-10-04 08:27:04+00:00        Miami        data analytics           2   \n",
       "\n",
       "                  updatedAt                       dob       industry  \\\n",
       "0 2024-04-05 00:19:07+00:00 1997-12-23 00:00:00+00:00         mining   \n",
       "1 2024-11-13 09:47:51+00:00 1970-11-25 01:56:10+00:00  manufacturing   \n",
       "2 2024-11-24 05:16:17+00:00 1981-12-11 10:34:33+00:00     healthcare   \n",
       "3 2024-10-12 08:43:58+00:00 1984-10-11 12:32:31+00:00     technology   \n",
       "4 2024-11-13 20:07:54+00:00 1981-04-08 12:52:15+00:00    hospitality   \n",
       "\n",
       "  profilePhoto   expertise                 createdAt  \\\n",
       "0       image1      python 2024-04-13 23:19:18+00:00   \n",
       "1     image378  JavaScript 2022-07-08 23:23:23+00:00   \n",
       "2     image915          C# 2023-06-14 14:25:21+00:00   \n",
       "3     image305         SQL 2020-03-10 07:22:15+00:00   \n",
       "4     image161      python 2023-07-05 08:48:00+00:00   \n",
       "\n",
       "                          email locationState locationCountry  \n",
       "0      matthewsdonald@yahoo.com       Toronto         Toronto  \n",
       "1     antoniowalker@example.com      New York        New York  \n",
       "2        fishermary@example.net   San Antonio     San Antonio  \n",
       "3  fergusonjennifer@example.com       Phoenix         Phoenix  \n",
       "4         marystout@example.org         Miami           Miami  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makeitmvp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
